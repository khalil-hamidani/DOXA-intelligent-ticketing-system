# Mapping: Processus M√©tier ‚Üî Architecture RAG + Agents

**Date**: December 22, 2025  
**Purpose**: Aligner le processus complet de traitement des tickets avec l'architecture RAG Pipeline + agents existants  
**Status**: ‚úÖ Mapping complet

---

## üìã Vue d'ensemble du processus m√©tier

```
Client soumet ticket
         ‚Üì
    [√âTAPE 0: VALIDATION] ‚Üê agents/validator.py
         ‚Üì
    [√âTAPE 1: SCORING] ‚Üê agents/scorer.py
         ‚Üì
    [√âTAPE 2: QUERY ANALYSIS] ‚Üê agents/query_analyzer.py + agents/classifier.py
         ‚Üì
    [√âTAPE 3: SOLUTION FINDING] ‚Üê pipeline/RAG (retrieval + ranking)
         ‚Üì
    [√âTAPE 4: EVALUATION] ‚Üê agents/evaluator.py
         ‚Üì
        / \
    Confiance? 
    / (>60%)  \
  OUI          NON
  ‚Üì             ‚Üì
[COMPOSER]  [ESCALADE]
  ‚Üì             ‚Üì
[ENVOYER]   [HUMAIN]
  ‚Üì             ‚Üì
[FEEDBACK]  [POST-ANALYSE]
  ‚Üì             ‚Üì
  ‚îî‚îÄ‚Üí [AM√âLIORATION CONTINUE] ‚Üê agents/continuous_improvement.py
         ‚Üì
    [FERMETURE]
```

---

## üîç Mapping d√©taill√© par √©tape

### **√âTAPE 0: Validation Initiale**

**Responsabilit√©**: V√©rifier que le ticket contient suffisamment d'information

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **V√©rification** | `agents/validator.py` | Agent Validator |
| **Input** | Ticket brut (formulaire client) | Client |
| **Checks** | Context, keywords, √©l√©ments exploitables | `QueryValidator` (pipeline) |
| **Output** | Ticket valide ‚úÖ ou Rejet√© ‚ùå | |
| **Action rejet** | Demander au client de compl√©ter | Client notification |

**Code existant**:
```python
# agents/validator.py
# v√©rifie: context_clarity, keyword_extractability, exploitability

# pipeline/query_intelligence.py ‚Üí QueryValidator
# valide: length, keywords, spam detection, low-signal queries
```

---

### **√âTAPE 1: Scoring & Priorisation**

**Responsabilit√©**: Calculer un score de priorit√© bas√© sur urgence, r√©currence, SLA

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Scoring** | `agents/scorer.py` | Agent Scorer |
| **Crit√®res** | Urgence, r√©currence, impact business, SLA | Config |
| **Output** | Score (0-100) ‚Üí Priorit√© file | |
| **Utilisation** | Ordonnance de traitement | Queue manager |

**Code existant**:
```python
# agents/scorer.py
# calcule: urgency_score, recurrence_score, business_impact_score
# g√©n√®re: ticket_priority
```

---

### **√âTAPE 2: Query Analysis**

**Responsabilit√©**: Comprendre le probl√®me du client (2 agents)

#### **Agent A: Analyse & Reformulation**

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **R√©sum√©** | `agents/query_analyzer.py` | Agent Query Analyzer |
| **Reformulation** | Pipeline input processing | |
| **Extraction keywords** | `pipeline/query_intelligence.py` ‚Üí `QueryAugmenter` | |
| **Output** | Ticket reformul√© + keywords | |

**Code existant**:
```python
# agents/query_analyzer.py
# r√©sume et reformule le ticket
# extrait les entit√©s et keywords

# pipeline/query_intelligence.py ‚Üí QueryAugmenter
# rephrasing, expansion, synonym extraction
```

#### **Agent B: Classification**

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Classification** | `agents/classifier.py` | Agent Classifier |
| **Cat√©gories** | technique, facturation, authentification, autre | |
| **Scores** | `pipeline/query_intelligence.py` ‚Üí `MulticlassClassifier` | Per-class scores |
| **Type traitement** | D√©termine route (support, billing, escalade...) | |
| **Output** | Cat√©gorie + type de traitement | |

**Code existant**:
```python
# agents/classifier.py
# classifie le ticket en cat√©gories

# pipeline/query_intelligence.py ‚Üí MulticlassClassifier
# per-class semantic scores (0-1)
# FIX: √©limine le probl√®me de "double classification"
```

---

### **√âTAPE 3: Solution Finding (RAG Core)**

**Responsabilit√©**: Trouver les documents KB pertinents et construire le contexte

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Query Encoding** | `pipeline/retrieval.py` ‚Üí `VectorRetriever` | Embeddings |
| **Vector Search** | `rag/vector_store.py` | Cosine similarity |
| **Document Retrieval** | `pipeline/retrieval.py` ‚Üí `ContextualRetriever` | Top-k + fallback |
| **Ranking** | `pipeline/ranking.py` ‚Üí `RankingPipeline` | 4 rankers |
| **Context Building** | `pipeline/context.py` ‚Üí `ContextBuilder` | Token-aware |
| **Output** | Context structur√© pour LLM | |

**Code existant - RAG Pipeline**:
```python
# pipeline/retrieval.py
# - embed query
# - search vector store
# - return results with similarity scores

# pipeline/ranking.py
# - semantic ranker (embedding similarity)
# - keyword ranker (BM25-like)
# - hybrid ranker (combinaison)
# - metadata ranker (category/priority/recency)

# pipeline/context.py
# - DocumentMerger (3 strategies)
# - ContextChunker (token-aware)
# - ContextOptimizer (greedy selection)
# - ContextBuilder (LLM-ready format)
```

**KB Data** (responsabilit√© data prep team):
```python
chunks = [
    {
        "id": "chunk_001",
        "content": "Solution/documentation text...",
        "metadata": {
            "category": "technique|facturation|authentification|autre",
            "section": "Installation|Troubleshooting|etc",
            "source": "help_docs|faq|manual",
            "priority": "high|medium|low"
        }
    }
]
```

---

### **√âTAPE 4: Evaluation & Confidence**

**Responsabilit√©**: √âvaluer la confiance de la solution trouv√©e

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Confiance** | `agents/evaluator.py` | Agent Evaluator |
| **Calcul** | Score de confiance (0-100%) | |
| **D√©tection** | Cas non-standards, √©motions, donn√©es sensibles | `ResponseValidator` (pipeline) |
| **D√©cision** | Confiance > 60% ? | |
| **Output** | Score + recommandation (r√©pondre ou escalader) | |

**Code existant**:
```python
# agents/evaluator.py
# calcule confidence_score
# d√©tecte anomalies, emotions, donn√©es sensibles

# pipeline/answer.py ‚Üí ResponseValidator
# v√©rifie answer_length, confidence_threshold
# d√©tecte escalation_indicators
```

---

### **√âTAPE 5: Response Composition (Confiance > 60%)**

**Responsabilit√©**: G√©n√©rer une r√©ponse structur√©e au client

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Input** | Ticket + contexte RAG | |
| **LLM Call** | `pipeline/answer.py` ‚Üí `ContextAwareAnswerGenerator` | Mistral |
| **Structure** | Remerciements, reformulation, solution, √©tapes | |
| **Output** | R√©ponse finale compl√®te | |

**Code existant**:
```python
# pipeline/answer.py
# - AnswerGenerator (LLM call via Agno)
# - ContextAwareAnswerGenerator (integrates context)
# - ResponseValidator (quality checks)

# agents/response_composer.py
# - formatte la r√©ponse finale
# - ajoute remerciements, structure
```

---

### **√âTAPE 6: Envoi & Feedback Client**

**Responsabilit√©**: Envoyer la r√©ponse et r√©colter le feedback

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Envoi** | Email send (notification) | |
| **Feedback** | Client satisfaction (oui/non) | Client |
| **Cas 1: ‚úÖ Satisfait** | Cl√¥ture ticket + archivage | |
| **Cas 2: ‚ùå Non satisfait** | Relance Query Analyzer (max 2 tentatives) | Loop back to step 2 |

**Code existant**:
```python
# agents/feedback_handler.py
# - r√©colte satisfaction client
# - d√©cide: cl√¥ture ou relance
# - compte max_attempts
```

---

### **√âTAPE 7: Escalade Humaine (Confiance < 60%)**

**Responsabilit√©**: Router vers agent humain si n√©cessaire

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Trigger** | Confiance < 60% OU max_attempts=2 atteint | |
| **Escalade** | `agents/escalation_manager.py` | Agent Escalation |
| **Assignation** | Routing vers support humain | Support team |
| **Email** | Notification automatique au client | |
| **Status** | "Escalad√© - En attente humain" | |

**Code existant**:
```python
# agents/escalation_manager.py
# - d√©tecte escalation triggers
# - assigne √† humain
# - cr√©e contexte escalade
# - envoie email client
```

---

### **√âTAPE 8: Post-analyse Humaine**

**Responsabilit√©**: Qualifier l'escalade

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Qualification** | Escalade justifi√©e ou non | Support humain |
| **Cat√©gories** | Hallucination IA, manque KB, donn√©es sensibles, etc. | |
| **Marquage** | Flag pour am√©lioration continue | DB |

**Code existant**:
```python
# agents/escalation_manager.py
# stocke escalade_reason, human_analysis
```

---

### **√âTAPE 9: Am√©lioration Continue**

**Responsabilit√©**: Analyser tous les escalad√©s, identifier patterns, enrichir KB

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Analyse** | `agents/continuous_improvment.py` | Agent CI |
| **Patterns** | D√©tecte probl√®mes r√©currents | |
| **KB Update** | Propose mise √† jour KB | Data team |
| **Hallucination** | D√©tecte & marque errors LLM | |
| **Feedback Cycle** | Alimente am√©lioration mod√®les | |

**Code existant**:
```python
# agents/continuous_improvment.py
# - analyse escalades
# - d√©tecte patterns
# - g√©n√®re KB_updates
# - marque hallucinations
```

---

### **√âTAPE 10: M√©triques & Reporting**

**Responsabilit√©**: Collecter et analyser les performances

| Aspect | Module | Responsable |
|--------|--------|-------------|
| **Satisfaction** | % tickets clients satisfaits | |
| **Escalade Rate** | % escalad√©s | |
| **Confiance** | Score moyen de confiance | |
| **Cycle time** | Temps r√©solution moyen | |
| **Quality** | √âvolution performance mod√®le | |

**Code existant**:
```python
# pipeline/orchestrator.py
# - RAGPipeline.get_stats()
# - r√©colte metrics par stage

# agents/feedback_handler.py
# - calcule satisfaction_rate
# - calcule escalation_rate
```

---

## üéØ Points d'int√©gration RAG Pipeline

### **1. O√π RAG intervient dans le flux**

```
√âtape 0: Validation
    ‚Üì
√âtape 1: Scoring + Classification
    ‚Üì
[ENTR√âE RAG] ‚Üê Query reformul√© + classified
    ‚Üì
√âtape 3: Solution Finding (RAG Core)
    ‚îú‚îÄ Query Intelligence (reformulation, augmentation)
    ‚îú‚îÄ Retrieval (semantic search on KB)
    ‚îú‚îÄ Ranking (4 strategies)
    ‚îî‚îÄ Context Building (token-aware)
    ‚Üì
√âtape 4: Evaluation (confiance sur r√©ponse RAG)
    ‚Üì
[SORTIE RAG] ‚Üí R√©ponse compl√®te + score de confiance
```

### **2. Input du RAG Pipeline**

```python
ticket = {
    "id": "t123",
    "category": "technique",  # From classifier
    "content": "Reformulated by query_analyzer",
    "keywords": ["keyword1", "keyword2"],  # From QueryAnalyzer
    "priority": 8,  # From scorer
    "client": {...}
}
```

### **3. Output du RAG Pipeline**

```python
result = {
    "stages": {
        "query_intelligence": {
            "validation": {...},
            "augmentation": {...},
            "classification": {...},
            "plan": {...}
        },
        "retrieval": {
            "query_embedding": [...],
            "results": [...],
            "similarity_scores": [0.87, 0.65, ...]
        },
        "ranking": {
            "method": "hybrid",
            "ranked_docs": [...],
            "scores": [...]
        },
        "context": {
            "merged_content": "...",
            "token_count": 1850,
            "document_count": 3
        },
        "answer": {
            "response": "Full answer to client",
            "confidence": 0.78
        },
        "validation": {
            "is_valid": True,
            "confidence_score": 0.78
        }
    },
    "final_response": "Full answer ready to send"
}
```

### **4. Confiance & Escalade Decision**

```python
confidence = result["stages"]["answer"]["confidence"]

if confidence < 0.60:
    # ESCALADE
    escalation_manager.escalate(ticket, confidence, reason)
else:
    # R√âPONDRE
    response_composer.compose(ticket, result["final_response"])
```

---

## üîÑ Loop de feedback (Max 2 tentatives)

```python
attempt = 1
max_attempts = 2

while attempt <= max_attempts:
    # √âtape 0-1: Validation + Scoring (unchanged)
    
    # √âtape 2: Query Analysis (reformulation diff√©rente possible)
    if attempt > 1:
        query_analyzer.reformulate_with_feedback(feedback)
    
    # √âtape 3: RAG Pipeline
    rag_result = rag.process_ticket(ticket)
    
    # √âtape 4: Evaluation
    confidence = rag_result["confidence"]
    
    if confidence > 0.60:
        # R√©pondre
        break
    elif attempt < max_attempts:
        # Relancer
        feedback = client_response["feedback"]
        attempt += 1
    else:
        # Escalader
        escalation_manager.escalate(ticket)
        break
```

---

## üìä Data Flow Complet

```
CLIENT FORM
    ‚Üì
[VALIDATOR] ‚Üí Valid? ‚úÖ
    ‚Üì
[SCORER] ‚Üí Priority score
    ‚Üì
[QUERY_ANALYZER] ‚Üí Reformulated query
    ‚Üì
[CLASSIFIER] ‚Üí Category + type
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     RAG PIPELINE (CORE)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Query Intelligence                   ‚îÇ
‚îÇ    - Validate (QueryValidator)          ‚îÇ
‚îÇ    - Augment (QueryAugmenter)           ‚îÇ
‚îÇ    - Classify (MulticlassClassifier)    ‚îÇ
‚îÇ    - Plan (QueryPlanner)                ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 2. Retrieval                            ‚îÇ
‚îÇ    - Embed query                        ‚îÇ
‚îÇ    - Search vector store                ‚îÇ
‚îÇ    - Filter by similarity               ‚îÇ
‚îÇ    - Multi-step fallback                ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 3. Ranking                              ‚îÇ
‚îÇ    - Semantic rank                      ‚îÇ
‚îÇ    - Keyword rank                       ‚îÇ
‚îÇ    - Hybrid rank                        ‚îÇ
‚îÇ    - Metadata rank                      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 4. Context                              ‚îÇ
‚îÇ    - Merge documents                    ‚îÇ
‚îÇ    - Chunk content                      ‚îÇ
‚îÇ    - Optimize for LLM window            ‚îÇ
‚îÇ    - Build prompt                       ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 5. Answer Generation                    ‚îÇ
‚îÇ    - LLM call (Mistral)                 ‚îÇ
‚îÇ    - Context integration                ‚îÇ
‚îÇ    - Validate response                  ‚îÇ
‚îÇ    - Score confidence                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
[EVALUATOR] ‚Üí Confidence score
    ‚Üì
        ‚ï± confidence > 60% ?
       ‚ï±           \
      ‚úÖ             ‚ùå
      ‚Üì              ‚Üì
  [COMPOSER]    [ESCALATION_MGR]
      ‚Üì              ‚Üì
  [SEND_EMAIL]  [HUMAN_AGENT]
      ‚Üì              ‚Üì
  [FEEDBACK_HANDLER] 
      ‚Üì
  Client satisfait? 
      ‚Üì
   ‚úÖ OUI: Cl√¥ture
   ‚ùå NON: Relance (max 2x)
      ‚Üì
[CONTINUOUS_IMPROVEMENT]
      ‚Üì
[METRICS & REPORTING]
```

---

## üí° Architecture Finale: Agents + RAG

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         TICKET MANAGEMENT SYSTEM                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                    ‚îÇ
‚îÇ  [VALIDATOR] ‚Üí [SCORER] ‚Üí [QUERY_ANALYZER]       ‚îÇ
‚îÇ                               ‚Üì                    ‚îÇ
‚îÇ                        [CLASSIFIER]               ‚îÇ
‚îÇ                               ‚Üì                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  RAG PIPELINE (CORE INTELLIGENCE)        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Query Intel ‚Üí Retrieval ‚Üí Ranking ‚Üí    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Context ‚Üí Answer Generation             ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                      ‚Üì                            ‚îÇ
‚îÇ              [EVALUATOR] (confidence)            ‚îÇ
‚îÇ                      ‚Üì                            ‚îÇ
‚îÇ              Confidence > 60%?                    ‚îÇ
‚îÇ              /                \                   ‚îÇ
‚îÇ           ‚úÖ YES             ‚ùå NO                 ‚îÇ
‚îÇ           ‚Üì                   ‚Üì                   ‚îÇ
‚îÇ      [COMPOSER]      [ESCALATION_MGR]           ‚îÇ
‚îÇ           ‚Üì                   ‚Üì                   ‚îÇ
‚îÇ      [SEND_EMAIL]      [HUMAN_HANDLING]         ‚îÇ
‚îÇ           ‚Üì                   ‚Üì                   ‚îÇ
‚îÇ      [FEEDBACK_HANDLER] ‚Üê feedback ‚Üê            ‚îÇ
‚îÇ           ‚Üì                                      ‚îÇ
‚îÇ     [CONTINUOUS_IMPROVEMENT]                    ‚îÇ
‚îÇ           ‚Üì                                      ‚îÇ
‚îÇ    [METRICS & REPORTING]                        ‚îÇ
‚îÇ                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ Checklist: Modules requis

### **Agents existants** ‚úÖ
- [x] `agents/validator.py` - Validation initiale
- [x] `agents/scorer.py` - Scoring & priorisation
- [x] `agents/query_analyzer.py` - Reformulation
- [x] `agents/classifier.py` - Classification
- [x] `agents/evaluator.py` - √âvaluation confiance
- [x] `agents/response_composer.py` - Composition r√©ponse
- [x] `agents/escalation_manager.py` - Escalade humaine
- [x] `agents/feedback_handler.py` - Feedback & boucle
- [x] `agents/continuous_improvment.py` - Am√©lioration KB
- [x] `agents/orchestrator.py` - Orchestration agents

### **RAG Pipeline** ‚úÖ
- [x] `pipeline/query_intelligence.py` - Query processing
- [x] `pipeline/retrieval.py` - Semantic search
- [x] `pipeline/ranking.py` - Document ranking
- [x] `pipeline/context.py` - Context optimization
- [x] `pipeline/answer.py` - LLM-based generation
- [x] `pipeline/orchestrator.py` - Full pipeline orchestration
- [x] `rag/embeddings.py` - Embedding models
- [x] `rag/vector_store.py` - Vector storage
- [x] `config/pipeline_config.py` - Configuration

### **Integration points** ‚úÖ
- [x] Query analyzer output ‚Üí RAG input
- [x] RAG output ‚Üí Evaluator input
- [x] Evaluator output ‚Üí Composer/Escalation decision
- [x] Feedback ‚Üí Query analyzer (loop)

---

## üéØ Summary: Mapping Process ‚Üí Code

| √âtape | Description | Primary Module | Secondary Modules |
|-------|-------------|-----------------|-------------------|
| **0** | Validation initiale | `validator.py` | `QueryValidator` (pipeline) |
| **1** | Scoring + Classification | `scorer.py` + `classifier.py` | `MulticlassClassifier` (pipeline) |
| **2** | Query Analysis | `query_analyzer.py` | `QueryAugmenter`, `QueryPlanner` (pipeline) |
| **3** | Solution Finding (RAG) | **RAG Pipeline** | `retrieval.py`, `ranking.py`, `context.py` |
| **4** | √âvaluation | `evaluator.py` | `ResponseValidator` (pipeline) |
| **5** | Composition | `response_composer.py` | `ContextAwareAnswerGenerator` (pipeline) |
| **6** | Envoi + Feedback | `feedback_handler.py` | |
| **7** | Escalade humaine | `escalation_manager.py` | |
| **8** | Post-analyse | `escalation_manager.py` | |
| **9** | Am√©lioration continue | `continuous_improvment.py` | |
| **10** | M√©triques | `orchestrator.py` | `RAGPipeline.get_stats()` |

---

## üöÄ Integration avec le RAG Pipeline

### **Cas d'usage 1: Utiliser RAG seul (Standalone)**
```python
from pipeline.orchestrator import SimplifiedRAGPipeline

rag = SimplifiedRAGPipeline()
rag.add_kb_documents(kb_chunks)

# Directement sans agents
answer = rag.answer_ticket(ticket)
```

### **Cas d'usage 2: Int√©grer RAG dans agents existants (Hybrid)**
```python
# agents/orchestrator.py
ticket = Ticket(...)

# √âtapes 0-2: Validation, Scoring, Analysis
validated = validator.validate(ticket)
scored = scorer.score(validated)
analyzed = query_analyzer.analyze(scored)
classified = classifier.classify(analyzed)

# √âtape 3: RAG Pipeline
from pipeline.orchestrator import RAGPipeline
rag = RAGPipeline()
rag_result = rag.process_ticket(analyzed)

# √âtapes 4+: Evaluation, Composition, Feedback
confidence = rag_result["stages"]["answer"]["confidence"]
if confidence > 0.60:
    composed = response_composer.compose(analyzed, rag_result)
    send_email(composed)
else:
    escalation_manager.escalate(analyzed, rag_result)
```

### **Cas d'usage 3: Remplacer agents par RAG (Progressive)**
```python
# Phase 1: Query Intelligence
# agents/query_analyzer + agents/classifier
# ‚Üì Remplacer par ‚Üì
# pipeline/query_intelligence.py (validation, augmentation, classification)

# Phase 2: Solution Finding
# agents/solution_finder (KB search)
# ‚Üì Remplacer par ‚Üì
# pipeline/retrieval + ranking + context (semantic RAG)

# Phase 3: Response
# agents/response_composer
# ‚Üì Utiliser ‚Üì
# pipeline/answer.py (LLM-based generation)
```

---

## üìù Notes importantes

### **1. Pas de duplication**
Le RAG Pipeline:
- ‚úÖ Utilise d√©j√† `query_intelligence.py` (analyse + classification)
- ‚úÖ Enrichit solution_finder (RAG retrieval)
- ‚úÖ G√©n√®re answers (LLM-based)
- ‚ùå Ne duplique PAS les agents existants

### **2. Compl√©mentarit√©**
- **Agents**: Orchestration m√©tier, d√©cisions, routing
- **RAG Pipeline**: Intelligence s√©mantique, retrieval, ranking

### **3. KB Data**
- Pr√©paration: Responsabilit√© **Data Prep Team**
- Format: Chunks avec metadata (category, section, source)
- Int√©gration: Une ligne: `rag.add_documents(chunks)`

### **4. Configuration**
Tous les param√®tres RAG sont configurables:
```python
# Environment ou programmatique
config = PipelineConfig(
    embedding_model="all-MiniLM-L6-v2",
    vector_store_type="chroma",
    ranker_type="hybrid",
    context_target_tokens=2000,
    retriever_top_k=5
)
```

### **5. Feedback Loop**
Le syst√®me supporte les boucles de feedback:
```
Attempt 1: Query ‚Üí RAG ‚Üí Confidence 0.45 ‚Üí Escalade
Attempt 2: Query (reformulated) ‚Üí RAG ‚Üí Confidence 0.75 ‚Üí R√©pondre
```

---

## üéâ Conclusion

Le **RAG Pipeline est con√ßu pour s'int√©grer naturellement** dans votre processus m√©tier:

‚úÖ **Couvre les √©tapes critiques**: Analyse s√©mantique, recherche KB, ranking, generation  
‚úÖ **Compl√©ment aux agents**: Ajoute intelligence IA √† l'orchestration existante  
‚úÖ **Non-breaking**: Peut coexister avec agents existants  
‚úÖ **Configurable**: Adapt√© √† votre contexte  
‚úÖ **Mesurable**: M√©triques int√©gr√©es √† chaque √©tape  

**Next step**: Int√©grer RAG dans `agents/orchestrator.py` pour automatiser √©tapes 2-4 du processus.
